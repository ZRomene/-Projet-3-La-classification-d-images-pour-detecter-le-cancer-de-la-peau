# -*- coding: utf-8 -*-
"""Skin_Cancer_Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NlAsw3tR_T_UgY3xG1TBVnT_BO1EsCAH

# Projet 3 "La classification d’images pour détecter le cancer de la peau"
###### Réalisé par : *Zaynab ROMENE*

Ressources: 
- https://notebook.community/frreiss/tensorflow-fred/tensorflow/lite/g3doc/tutorials/model_maker_image_classification 
- https://levelup.gitconnected.com/custom-image-classification-model-using-tensorflow-lite-model-maker-68ee4514cd45
- https://stackoverflow.com/questions/65438156/tensorflow-keras-error-unknown-image-file-format-one-of-jpeg-png-gif-bmp-re
- https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb?hl=fr#scrollTo=H74l2DoDI2XD 
- https://notebook.community/frreiss/tensorflow-fred/tensorflow/lite/g3doc/tutorials/model_maker_image_classification

Le but de ce projet est d'analyser les images afin de détecter la présence d'un cancer de la peau. Puisque c'est un projet académique, on s'est concentré sur un seul type de cancer "le mélanome". Il s'agit alors d'une classification binaire. C'est-à-dire l'algorithme détecte s'il s'agit d'un cancer mélanome ou bien un cas normal.

Nous devons d'abord installer plusieurs packages requis, y compris le package Model Maker.
"""

!sudo apt -y install libportaudio2
!pip install -q tflite-model-maker

"""On importe par la suite les packages requis."""

import os

import numpy as np

import tensorflow as tf
assert tf.__version__.startswith('2')

from tflite_model_maker import model_spec
from tflite_model_maker import image_classifier
from tflite_model_maker.config import ExportFormat
from tflite_model_maker.config import QuantizationConfig
from tflite_model_maker.image_classifier import DataLoader

import matplotlib.pyplot as plt

"""On définit le chemin d'accès à notre données d'image. Dans mon cas, j'ai mis toute la base de données dans /content/drive/MyDrive/Dataset"""

import os

root_path = "/content/drive/MyDrive/"    
image_path = os.path.join(os.path.dirname(root_path), 'Dataset/')
print (image_path)

!rmdir /content/drive/MyDrive/Dataset/Cancer_Skin/.ipynb_checkpoints
!rmdir /content/drive/MyDrive/Dataset/Safe_Skin/.ipynb_checkpoints
!rmdir /content/drive/MyDrive/Dataset/.ipynb_checkpoints

"""On fait une première répartition de données 80/20 entre les données d'entraînement et les données de test."""

data = DataLoader.from_folder(image_path)
train_data, rest_data = data.split(0.8)

"""On fait une deuxième répartition 50/50 des données de test qui restent en "test_data" et "validation_data"
"""

validation_data, test_data = rest_data.split(0.5)

"""On peut afficher 25 exemples d'images avec des étiquettes (labels) juste pour vérifier que les deux classes (catégories) d'images ont été bien lues."""

plt.figure(figsize=(10,10))
for i, (image, label) in enumerate(data.gen_dataset().unbatch().take(25)):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(image.numpy(), cmap=plt.cm.gray)
  plt.xlabel(data.index_to_label[label.numpy()])
plt.show()

!pip install tensorflow==2.7

"""Python a de nombreux modules dans sa bibliothèque standard, et celui qui aide ici est imghdr. Il vous permet d'identifier le type d'image contenu dans un fichier. L'imghdr peut reconnaître les types d'images suivants : rgb, gif, pbm, pgm, ppm, tiff, rast, xbm, jpeg/jpg, bmp, png, webp et exr.  C'est indispensable de vérifier si l'image est utilisable ou non avant de générer le modèle.
On peut rechercher un type d'image, pas un nom d'extension, par le code suivant: 
"""

import os
import cv2
import imghdr

def check_images( s_dir, ext_list):
    bad_images=[]
    bad_ext=[]
    s_list= os.listdir(s_dir)
    for klass in s_list:
        klass_path=os.path.join (s_dir, klass)
        print ('processing class directory ', klass)
        if os.path.isdir(klass_path):
            file_list=os.listdir(klass_path)
            for f in file_list:               
                f_path=os.path.join (klass_path,f)
                tip = imghdr.what(f_path)
                if ext_list.count(tip) == 0:
                  bad_images.append(f_path)
                if os.path.isfile(f_path):
                    try:
                        img=cv2.imread(f_path)
                        shape=img.shape
                    except:
                        print('file ', f_path, ' is not a valid image file')
                        bad_images.append(f_path)
                else:
                    print('*** fatal error, you a sub directory ', f, ' in class directory ', klass)
        else:
            print ('*** WARNING*** you have files in ', s_dir, ' it should only contain sub directories')
    return bad_images, bad_ext

source_dir =r'/content/drive/MyDrive/Dataset/'
good_exts=['jpg', 'png', 'jpeg', 'gif', 'bmp' ] # list of acceptable extensions
bad_file_list, bad_ext_list=check_images(source_dir, good_exts)
if len(bad_file_list) !=0:
    print('improper image files are listed below')
    for i in range (len(bad_file_list)):
        print (bad_file_list[i])
else:
    print(' no improper image files were found')

"""On passe maintenant à l'entraînement du modèle. Les paramaitres sont: 

- Les données d'entraînement seront utilisées pour réellement former le modèle. 
- Les données de validation seront utilisées pour vérifier les performances du modèle après chaque cycle d'entraînement.
-Le nombre d'époques qui définit le nombre de cycles d'entraînement (plus il y a d'époques, plus votre modèle mettra de temps à s'entraîner)
- La spécification du modèle qui est un modèle d'image générique pré-entraîné.
"""

model = image_classifier.create(train_data, model_spec=model_spec.get('efficientnet_lite0'), validation_data=validation_data, epochs = 20)

"""Une fois que le modèle a fini de s'exécuter, on peut l'évaluer par rapport aux "test_data" qu'il n'a jamais vus auparavant."""

loss, accuracy = model.evaluate(test_data)

"""Ensuite, On convertit le modèle existant au format de modèle TensorFlow Lite et on enregistre les étiquettes d'image dans le fichier d'étiquettes (labels). Le nom de fichier TFLite par défaut est model.tflite, le nom de fichier d'étiquette ( fichier qui contient les labels) est label.txt."""

model.export(export_dir='.')

"""Voici la structure détaillée du modèle:"""

model.summary()

"""On peut remarquer maintenant un fichier model.tflite dans le dossier '/content/'. 
 Pour accéder aux données sérialisées de notre programme, nous devons les compiler dans l'exécutable et les stocker en Flash. La façon la plus simple de le faire est de convertir le fichier en un tableau de données C.
Ceci peut être fait par les commandes suivantes:

"""

# Install xxd if it is not available
! apt-get -qq install xxd
# Save the file as a C source file
! xxd -i model.tflite > model_data.cc

"""Afin de réduire la taille de modèle, il est commode de l'optimiser. La quantification post-formation est une technique de conversion qui peut réduire la taille du modèle et la latence d’inférence, tout en améliorant la latence du processeur et de l’accélérateur matériel, avec peu de dégradation de la précision du modèle. """

config = QuantizationConfig.for_int8(representative_data=test_data)

model.export(export_dir='.', tflite_filename='model_quant.tflite', quantization_config=config)

# Install xxd if it is not available
! apt-get -qq install xxd
# Save the file as a C source file
! xxd -i model_quant.tflite > model_quant_data.cc